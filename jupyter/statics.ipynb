{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "categories = ['Airport', 'City', 'Company', 'Compound', 'Conference', 'Lake', 'Person']\n",
    "idx = 6\n",
    "\n",
    "preds_path = f'../outputs/sample/{categories[idx]}.json'\n",
    "baseline_path = f'../outputs/sample/el_baseline/{categories[idx]}.json'\n",
    "# baseline_path = f'../outputs/sample/el_wo_exact/{categories[idx]}.json'\n",
    "true_path = f'/data1/ujiie/shinra/EN/linkjp-sample-210402/link_annotation/{categories[idx]}.json'\n",
    "tmp_path = '../outputs/tmp.json'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "import json\n",
    "base = []\n",
    "with open(baseline_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = json.loads(line)\n",
    "        base.append(line)\n",
    "\n",
    "print(len(base))\n",
    "base_set = set([(p['page_id'], p['html_offset']['start']['line_id'], p['html_offset']['start']['offset']) for p in base])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1626\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "import json\n",
    "trues = []\n",
    "with open(true_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = json.loads(line)\n",
    "        trues.append(line)\n",
    "print(len(trues))\n",
    "true_set = set([(p['page_id'], p['html_offset']['start']['line_id'], p['html_offset']['start']['offset']) for p in trues])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1731\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "preds = []\n",
    "with open(preds_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = json.loads(line)\n",
    "        preds.append(line)\n",
    "print(len(preds))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3326\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "import sys\n",
    "sys.path.append('/home/is/ujiie')\n",
    "import linkjp_scorer\n",
    "from linkjp_scorer.scorer.core import micro_average\n",
    "\n",
    "thresholds = list(range(-20, 21))\n",
    "\n",
    "max_thre = - float('inf')\n",
    "max_f1 = - float('inf')\n",
    "scores = None\n",
    "\n",
    "for thre in thresholds:\n",
    "    with open(tmp_path, 'w') as f:\n",
    "        for b in base:\n",
    "            b['page_id'] = str(b['page_id'])\n",
    "            f.write(json.dumps(b, ensure_ascii=False) + '\\n')\n",
    "\n",
    "        for p in preds:\n",
    "            p['page_id'] = str(p['page_id'])\n",
    "            cand = (str(p['page_id']), p['html_offset']['start']['line_id'], p['html_offset']['start']['offset'])\n",
    "            if cand in base_set:\n",
    "                continue\n",
    "\n",
    "\n",
    "            if p['score'] > thre:\n",
    "                f.write(json.dumps(p, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    scorer = linkjp_scorer.Scorer(linkjp_scorer.Category.PERSON,\n",
    "                                    true_path, tmp_path)\n",
    "    scorer.calc_score()\n",
    "    s = micro_average(scorer.counter.values())\n",
    "    f1 = s.f1\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        max_thre = thre\n",
    "        scores = (s.precision, s.recall, s.f1)\n",
    "max_f1, max_thre, scores\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.50238379022646,\n",
       " -20,\n",
       " (0.518450184501845, 0.48728323699421966, 0.50238379022646))"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bertのみ\n",
    "- Airport 5, 0.658\n",
    "- City 4, 0.700\n",
    "- COMPANY 6, 0.557\n",
    "- COMPOUND 4, 0.535\n",
    "- CONFERENCE 3, 0.721\n",
    "- LAKE 3, 0.733\n",
    "- PERSON 6, 0.526\n",
    "\n",
    "## baseline\n",
    "- Airport null, 0.839\n",
    "- City null, 0.682\n",
    "- COMPANY null, 0.545\n",
    "- COMPOUND null, 0.845\n",
    "- CONFERENCE null, 0.713\n",
    "- LAKE null, 0.761\n",
    "- PERSON null, 0.502\n",
    "\n",
    "## baseline + bert\n",
    "- Airport 10, 0.852\n",
    "- CITY 12, 0.684\n",
    "- COMPANY 9, 0.574\n",
    "- COMPOUND 14, 0.851\n",
    "- CONFERENCE 12, 0.715\n",
    "- LAKE 10, 0.766\n",
    "- PERSON 9, 0.513\n",
    "\n",
    "## baseline wo exact match\n",
    "- Airport null, 0.558\n",
    "- CITY null, 0.169\n",
    "- COMPANY null, 0.201\n",
    "- COMPOUND null, 0.657\n",
    "- CONFERENCE null, 0.125\n",
    "- LAKE null, 0.206\n",
    "- PERSON null, 0.127\n",
    "\n",
    "## baseline wo exact match + bert\n",
    "- Airport 5, 0.855\n",
    "- CITY 4, 0.721\n",
    "- COMPANY 6, 0.583\n",
    "- COMPOUND 9, 0.837\n",
    "- CONFERENCE 4, 0.732\n",
    "- LAKE 5, 0.777\n",
    "- PERSON 6, 0.552"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "idx = 6\n",
    "thre = 6\n",
    "\n",
    "categories = ['Airport', 'City', 'Company', 'Compound', 'Conference', 'Lake', 'Person']\n",
    "preds_path = f'../outputs/{categories[idx]}.json'\n",
    "baseline_path = f'../outputs/el_wo_exact/{categories[idx]}.json'\n",
    "output_path = f'../outputs/eval_only_bert/{categories[idx]}.json'\n",
    "\n",
    "\n",
    "base = []\n",
    "with open(baseline_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = json.loads(line)\n",
    "        base.append(line)\n",
    "# base_set = set([(p['page_id'], p['html_offset']['start']['line_id'], p['html_offset']['start']['offset'], p['html_offset']['end']['offset']) for p in base])\n",
    "base_set = set([(p['page_id'], p['html_offset']['start']['line_id'], p['html_offset']['start']['offset'], p['html_offset']['end']['offset']) for p in base])\n",
    "print(len(base_set))\n",
    "\n",
    "preds = []\n",
    "with open(preds_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = json.loads(line)\n",
    "        preds.append(line)\n",
    "print(len(preds))\n",
    "cnt = 0\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    for b in base:\n",
    "        b['page_id'] = str(b['page_id'])\n",
    "        f.write(json.dumps(b, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    for p in preds:\n",
    "        p['page_id'] = str(p['page_id'])\n",
    "        cand = (str(p['page_id']), p['html_offset']['start']['line_id'], p['html_offset']['start']['offset'], p['html_offset']['end']['offset'])\n",
    "        if cand in base_set:\n",
    "            cnt += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        if p['score'] > thre:\n",
    "            del p['score']\n",
    "            del p['candidates']\n",
    "            f.write(json.dumps(p, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(cnt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "422\n",
      "4026\n",
      "449\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  },
  "interpreter": {
   "hash": "387fc777c06daa4bf266a6aa93c40b9095b849dc57748116e63a1f5b6f7d760f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}